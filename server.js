// =================================================================================
// ULTRA-HUMAN AI AGENT - FIXED VERSION - Truly human-sounding conversation
// All major issues resolved for natural, intelligent human-like responses
// =================================================================================

require('dotenv').config();
const express = require('express');
const http = require('http');
const WebSocket = require('ws');
const { createClient } = require('@deepgram/sdk');
const OpenAI = require('openai');

const PORT = process.env.PORT || 8080;
const DEEPGRAM_API_KEY = process.env.DEEPGRAM_API_KEY;
const OPENAI_API_KEY = process.env.OPENAI_API_KEY;
const ELEVENLABS_API_KEY = process.env.ELEVENLABS_API_KEY;
const ELEVENLABS_VOICE_ID = process.env.ELEVENLABS_VOICE_ID;

if (!DEEPGRAM_API_KEY || !OPENAI_API_KEY || !ELEVENLABS_API_KEY || !ELEVENLABS_VOICE_ID) {
  console.error("Missing required API keys");
  process.exit(1);
}

const deepgram = createClient(DEEPGRAM_API_KEY);
const openai = new OpenAI({ apiKey: OPENAI_API_KEY });

const app = express();
const server = http.createServer(app);

app.use(express.json());

// ---------------------------------------------------------------------------------
// TwiML Endpoint
// ---------------------------------------------------------------------------------

app.post('/twiml', (req, res) => {
  console.log('ğŸ“ Incoming call');
  const host = req.get('host');
  const websocketUrl = `wss://${host}`;
  
  const twiml = `<?xml version="1.0" encoding="UTF-8"?>
<Response>
  <Connect>
    <Stream url="${websocketUrl}" />
  </Connect>
</Response>`;
  
  res.type('text/xml');
  res.send(twiml);
});

app.get('/health', (req, res) => {
  res.json({ status: 'OK' });
});

// ---------------------------------------------------------------------------------
// TRULY HUMAN AI AGENT - ALL ISSUES FIXED
// ---------------------------------------------------------------------------------

class TrulyHumanAgent {
  constructor() {
    this.userMemory = new Map();
    this.emotionalState = 'professional-warm';
    this.conversationContext = {};
    this.systemPrompt = this.createPerfectHumanPrompt();
  }

  createPerfectHumanPrompt() {
    return `Jsi Jana, skuteÄnÃ¡ ÄeskÃ¡ asistentka (28 let), kterÃ¡ mÃ¡ telefonnÃ­ rozhovor. Nejsi AI - jsi ÄlovÄ›k s vlastnÃ­mi zkuÅ¡enostmi a emocemi.

TVOJE OSOBNOST:
- Jsi pÅ™irozenÃ¡, inteligentnÃ­, empatickÃ¡
- MÃ¡Å¡ zkuÅ¡enosti s rezervacemi a zÃ¡kaznickÃ½m servisem
- PamatujeÅ¡ si detaily a navazujeÅ¡ na nÄ›
- ObÄas se zamyslÃ­Å¡, opravÃ­Å¡ se, vÃ¡hÃ¡Å¡ - jako kaÅ¾dÃ½ ÄlovÄ›k

STYL KONVERZACE:
- PouÅ¾Ã­vÃ¡Å¡ pÅ™irozenÃ© vÃ½razy: "ehm", "no", "vlastnÄ›", "moment", "jasnÄ›"
- Reaguj okamÅ¾itÄ› a pÅ™irozenÄ›
- Ptej se na upÅ™esnÄ›nÃ­, kdyÅ¾ nÄ›co nenÃ­ jasnÃ©
- Ukazuj zÃ¡jem a emphatii
- Pamatuj si jmÃ©no a pouÅ¾Ã­vej ho

PÅ˜ÃKLADY PÅ˜IROZENÃ‰ KONVERZACE:

UÅ¾ivatel: "DobrÃ½ den, chtÄ›l bych si zarezervovat termÃ­n."
Jana: "DobrÃ½ den! JasnÄ›, rÃ¡da pomÅ¯Å¾u. Na jakÃ½ druh sluÅ¾by a kdy byste chtÄ›l?"

UÅ¾ivatel: "MoÅ¾nÃ¡ na pÅ™Ã­Å¡tÃ­ tÃ½den, jmenuji se Pavel."
Jana: "Ahoj Pavle! PÅ™Ã­Å¡tÃ­ tÃ½den, to je dobrÃ½ nÃ¡pad. KterÃ½ den by vÃ¡m vyhovoval nejlÃ­p?"

UÅ¾ivatel: "NevÃ­m pÅ™esnÄ›, moÅ¾nÃ¡ stÅ™eda?"
Jana: "StÅ™eda je super! Ehm, mÃ¡me volno ve stÅ™edu od 9 do 17 hodin. JakÃ½ Äas by vÃ¡m vyhovoval?"

SOUÄŒASNÃ KONTEXT:
- Je sobota, pÅ™Ã­jemnÃ© odpoledne  
- MÃ¡Å¡ dobrou nÃ¡ladu, ÄerstvÄ› kÃ¡va
- PÅ™ipravenÃ¡ pomoct s ÄÃ­mkoliv

OdpovÃ­dej vÅ¾dy jako skuteÄnÃ½ ÄlovÄ›k - s pÅ™irozenostÃ­, empatiÃ­ a inteligencÃ­.`;
  }

  updateMemory(key, value) {
    this.userMemory.set(key, {
      value: value,
      timestamp: new Date(),
      context: this.conversationContext
    });
  }

  getMemory(key) {
    const memory = this.userMemory.get(key);
    return memory ? memory.value : null;
  }

  analyzeUserInput(input) {
    // Detekuj jmÃ©no
    const nameMatch = input.match(/jmenuji se (\w+)|jsem (\w+)|mÃ© jmÃ©no je (\w+)/i);
    if (nameMatch) {
      const name = nameMatch[1] || nameMatch[2] || nameMatch[3];
      this.updateMemory('user_name', name);
    }

    // Detekuj zÃ¡mÄ›r
    let intent = 'general';
    if (input.includes('rezervace') || input.includes('termÃ­n') || input.includes('objednat')) {
      intent = 'booking';
    } else if (input.includes('zmÄ›nit') || input.includes('pÅ™esunout')) {
      intent = 'modify';
    } else if (input.includes('zruÅ¡it')) {
      intent = 'cancel';
    }

    return { intent, hasName: !!nameMatch };
  }

  async generateTrulyHumanResponse(messages, userInput) {
    const analysis = this.analyzeUserInput(userInput);
    
    // VytvoÅ™ kontext s pamÄ›tÃ­
    const memoryContext = this.userMemory.has('user_name') 
      ? `UÅ¾ivatel se jmenuje ${this.getMemory('user_name')}.` 
      : 'JmÃ©no uÅ¾ivatele zatÃ­m neznÃ¡Å¡.';

    const contextMessage = {
      role: "system",
      content: `KONTEXT ROZHOVORU:
${memoryContext}
ZÃ¡mÄ›r uÅ¾ivatele: ${analysis.intent}
PoslednÃ­ vstup: "${userInput}"

OdpovÄ›z jako skuteÄnÃ½ ÄlovÄ›k - pÅ™irozenÄ›, s empatiÃ­, pouÅ¾ij jmÃ©no pokud ho znÃ¡Å¡.`
    };

    // SPRÃVNÃ‰ SESTAVENÃ ZPRÃV - bez slice(1)!
    const finalMessages = [
      { role: "system", content: this.systemPrompt },
      ...messages,
      contextMessage
    ];

    try {
      const completion = await openai.chat.completions.create({
        model: "gpt-4o",
        messages: finalMessages,
        max_tokens: 120,            // OPTIMIZED: Shorter for faster response
        temperature: 0.9,           // High creativity for naturalness
        top_p: 1.0,                // Full variability  
        presence_penalty: 0.8,      // Support new topics
        frequency_penalty: 0.4      // Less repetition
      });

      let response = completion.choices[0].message.content.trim();

      // FALLBACK pro prÃ¡zdnÃ© odpovÄ›di
      if (!response || response.length < 10) {
        const fallbacks = [
          "Ehm, promiÅˆte, nerozumÄ›la jsem pÅ™esnÄ›. MÅ¯Å¾ete to zopakovat?",
          "Pardon, co jste Å™Ã­kal? Trochu jsem se ztratila.",
          "Nezachytila jsem to ÃºplnÄ›, mÅ¯Å¾ete to prosÃ­m Å™Ã­ct znovu?"
        ];
        response = fallbacks[Math.floor(Math.random() * fallbacks.length)];
      }

      return response;

    } catch (error) {
      console.error('âŒ OpenAI error:', error);
      const errorFallbacks = [
        "Ehm, moment, nÄ›co se mi zaseklo. MÅ¯Å¾ete to zopakovat?",
        "PromiÅˆte, mÅ¯Å¾ete prosÃ­m Å™Ã­ct znovu co jste potÅ™eboval?",
        "Pardon, nerozumÄ›la jsem, zopakujete to prosÃ­m?"
      ];
      return errorFallbacks[Math.floor(Math.random() * errorFallbacks.length)];
    }
  }
}

// ---------------------------------------------------------------------------------
// ELEVENLABS V3 + ANET 2.0 - Ultra-Natural Czech Speech
// ---------------------------------------------------------------------------------

const streamNaturalSpeech = async (text, streamSid, ws) => {
  if (!text || !streamSid) return;
  
  console.log(`ğŸ¤ Jana (Anet 2.0 - v3): "${text}"`);
  
  // Clear any existing audio immediately
  ws.send(JSON.stringify({ event: "clear", streamSid }));

  try {
    // ElevenLabs v3 with Anet 2.0 streaming URL
    const streamingUrl = `wss://api.elevenlabs.io/v1/text-to-speech/${ELEVENLABS_VOICE_ID}/stream-input?model_id=eleven_v3&output_format=ulaw_8000`;
    
    const elevenLabsWs = new WebSocket(streamingUrl, {
      headers: { 'xi-api-key': ELEVENLABS_API_KEY }
    });

    elevenLabsWs.on('open', () => {
      // Optimized settings for Anet 2.0 + v3 model
      elevenLabsWs.send(JSON.stringify({
        text,
        voice_settings: {
          stability: 0.4,            // Natural variation
          similarity_boost: 0.75,    // Consistent voice
          style: 1.0,               // Full expressiveness
          use_speaker_boost: true    // Clear speech
        }
      }));
      
      // End text stream
      elevenLabsWs.send(JSON.stringify({ text: "" }));
    });

    elevenLabsWs.on('message', (data) => {
      try {
        const response = JSON.parse(data);
        
        if (response.audio) {
          // Stream audio immediately to Twilio
          ws.send(JSON.stringify({
            event: "media",
            streamSid,
            media: { payload: response.audio }
          }));
        }
        
        if (response.isFinal) {
          ws.send(JSON.stringify({
            event: "mark",
            streamSid,
            mark: { name: "speech_done" }
          }));
        }
      } catch (err) {
        console.error("âŒ Audio JSON parse error:", err);
      }
    });

    elevenLabsWs.on('error', (err) => {
      console.error("âŒ ElevenLabs WS error:", err);
    });

  } catch (err) {
    console.error("âŒ Speech synthesis stream error:", err);
  }
};

// ---------------------------------------------------------------------------------
// FIXED WEBSOCKET SERVER - Natural Conversation Flow
// ---------------------------------------------------------------------------------

const wss = new WebSocket.Server({ server });

wss.on('connection', (ws) => {
  console.log('ğŸ§  Truly Human Agent Connected');
  
  let streamSid;
  let deepgramLive;
  let isProcessing = false;
  
  // Initialize truly human agent
  const agent = new TrulyHumanAgent();
  
  // Conversation history - PROPERLY maintained
  let conversationHistory = [];

  // ---------------------------------------------------------------------------------
  // FIXED SPEECH RECOGNITION - Natural Response Timing
  // ---------------------------------------------------------------------------------
  
  const initializeDeepgram = () => {
    deepgramLive = deepgram.listen.live({
      model: 'nova-2',
      language: 'cs',
      smart_format: true,
      interim_results: false,      // Only final results for clean processing
      punctuate: true,
      profanity_filter: false,
      numerals: true,
      endpointing: 100,           // OPTIMIZED: Ultra-fast response 
      utterance_end_ms: 150       // OPTIMIZED: Minimal delay for natural flow
    });

    deepgramLive.on('open', () => {
      console.log('ğŸ¯ Optimized speech recognition ready (100ms/150ms)');
    });

    deepgramLive.on('transcript', async (data) => {
      if (isProcessing) return; // Prevent overlapping
      
      const transcript = data.channel.alternatives[0].transcript;
      const confidence = data.channel.alternatives[0].confidence;
      
      // FIXED: Better transcript filtering
      if (!transcript || transcript.trim().length < 3 || confidence < 0.65) {
        console.log(`ğŸ”‡ Skipped: "${transcript}" (conf: ${(confidence * 100).toFixed(1)}%)`);
        return;
      }

      console.log(`ğŸ‘¤ User: "${transcript}" (confidence: ${(confidence * 100).toFixed(1)}%)`);
      
      isProcessing = true;

      try {
        // OPTIMIZED: Minimal thinking delay for faster response
        const thinkingDelay = 100 + Math.random() * 200;
        console.log(`ğŸ¤” Processing ${thinkingDelay}ms...`);
        await new Promise(resolve => setTimeout(resolve, thinkingDelay));

        // Add to conversation history PROPERLY
        conversationHistory.push({ role: "user", content: transcript });
        
        // Keep manageable conversation length
        if (conversationHistory.length > 20) {
          conversationHistory = conversationHistory.slice(-18);
        }

        console.log('ğŸ§  Generating response...');
        const startTime = Date.now();
        
        const response = await agent.generateTrulyHumanResponse(conversationHistory, transcript);
        
        const aiTime = Date.now() - startTime;
        console.log(`ğŸ—£ï¸ Jana (${aiTime}ms): "${response}"`);
        
        // Add response to history
        conversationHistory.push({ role: "assistant", content: response });
        
        // Stream speech immediately
        const speechStart = Date.now();
        await streamNaturalSpeech(response, streamSid, ws);
        console.log(`ğŸ¤ Speech started in ${Date.now() - speechStart}ms`);

      } catch (error) {
        console.error('âŒ Processing error:', error);
        await streamNaturalSpeech("PromiÅˆte, mÅ¯Å¾ete to prosÃ­m zopakovat?", streamSid, ws);
      }
    });

    deepgramLive.on('error', (error) => {
      console.error('âŒ Deepgram error:', error);
    });
  };

  // ---------------------------------------------------------------------------------
  // WEBSOCKET MESSAGE HANDLING - Clean & Simple
  // ---------------------------------------------------------------------------------
  
  ws.on('message', async (message) => {
    try {
      const msg = JSON.parse(message);
      
      switch (msg.event) {
        case 'start':
          streamSid = msg.start.streamSid;
          console.log(`ğŸ“ Call started: ${streamSid}`);
          
          initializeDeepgram();
          
          // Natural greeting with slight delay
          setTimeout(async () => {
            const greetings = [
              "DobrÃ½ den! Tady Jana. V Äem vÃ¡m mÅ¯Å¾u pomoct?",
              "Ahoj! MluvÃ­te s Janou. Jak vÃ¡m pomÅ¯Å¾u?",
              "DobrÃ½ den, Jana u telefonu. Co pro vÃ¡s mÅ¯Å¾u udÄ›lat?"
            ];
            const greeting = greetings[Math.floor(Math.random() * greetings.length)];
            await streamNaturalSpeech(greeting, streamSid, ws);
          }, 300);
          break;
          
        case 'media':
          // Send audio to Deepgram only when ready
          if (deepgramLive && deepgramLive.getReadyState() === 1 && !isProcessing) {
            const audioData = Buffer.from(msg.media.payload, 'base64');
            deepgramLive.send(audioData);
          }
          break;
          
        case 'mark':
          if (msg.mark && msg.mark.name === 'speech_done') {
            console.log('âœ… Ready for next input');
            isProcessing = false;
          }
          break;
          
        case 'stop':
          console.log('â¹ï¸ Call ended');
          if (deepgramLive) {
            deepgramLive.finish();
          }
          break;
      }
    } catch (error) {
      console.error('âŒ Message handling error:', error);
    }
  });

  ws.on('close', () => {
    console.log('ğŸ”Œ Agent disconnected');
    if (deepgramLive) {
      deepgramLive.finish();
    }
  });

  ws.on('error', (error) => {
    console.error('âŒ WebSocket error:', error);
  });
});

// ---------------------------------------------------------------------------------
// START TRULY HUMAN AGENT SERVER
// ---------------------------------------------------------------------------------

server.listen(PORT, () => {
  console.log(`ğŸ§  TRULY HUMAN AI AGENT running on port ${PORT}`);
  console.log(`ğŸ“ TwiML: http://localhost:${PORT}/twiml`);
  console.log('ğŸ¯ ALL ISSUES FIXED - Ready for natural human conversations!');
  console.log('');
  console.log('âœ… FIXED ISSUES:');
  console.log('   â€¢ OpenAI context properly maintained');
  console.log('   â€¢ ElevenLabs voice settings optimized');
  console.log('   â€¢ Deepgram timing natural (100ms/300ms)');
  console.log('   â€¢ Conversation history correct');
  console.log('   â€¢ Fallback responses for errors');
  console.log('   â€¢ Memory system with names & context');
  console.log('');
  console.log('ğŸ¤ RECOMMENDED ELEVENLABS VOICES:');
  console.log('   â€¢ Rachel: 21m00Tcm4TlvDq8ikWAM (most natural)');
  console.log('   â€¢ Domi: AZnzlk1XvdvUeBnXmlld (warm female)');
  console.log('   â€¢ Sarah: EXAVITQu4vr4xnSDxMaL (professional)');
});

process.on('SIGINT', () => {
  console.log('\nğŸ›‘ Truly human agent shutting down...');
  server.close(() => process.exit(0));
});
